# -*- coding: utf-8 -*-
"""Liza Meem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10_EU561RJXv3lalvm4gqlNXpyijWf1Ox
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
import pandas as pd

df = pd.read_csv("F:\\Research\\New folder\\Liza Meem\\Lungcancer3.csv")

df.head(10)

df.info()

df['LUNG_CANCER'].value_counts()

df['LUNG_CANCER']=df['LUNG_CANCER'].map({'YES':1,'NO':0})

df['GENDER']=df['GENDER'].map({'M':1,'F':2})

df.shape



#sns.countplot(df['Selectorfield'],label='value')
sns.countplot(df.LUNG_CANCER,palette=["#FF0000","#0000FF"])
#plt.title("[1]----> Secondery Stage  [0]----> Primary Stage"):
plt.ylabel('Combination of two stages values')
plt.xlabel('Predicted_attriute')

df.columns

prediction_var = ['GENDER', 'AGE', 'SMOKING', 'YELLOW_FINGERS', 'ANXIETY',
       'PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING',
       'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',
       'SWALLOWING DIFFICULTY', 'CHEST PAIN']

from sklearn.model_selection import train_test_split

train, test = train_test_split(df, test_size = 0.2)# in this our main data is splitted into train and test
# we can check their dimension
print(train.shape)
print(test.shape)

train_X = train[prediction_var]# taking the training data input
train_y=train.LUNG_CANCER# This is output of our training data
# same we have to do for test
test_X= test[prediction_var] # taking test data inputs
test_y =test.LUNG_CANCER   #output value of test dat

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL
import matplotlib.pyplot as plt # this is used for the plot the graph
import seaborn as sns # used for plot interactive graph. I like it most for plot
# %matplotlib inline
from sklearn.linear_model import LogisticRegression # to apply the Logistic regression
from sklearn.model_selection import train_test_split # to split the data into two parts
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV# for tuning parameter
from sklearn.ensemble import RandomForestClassifier # for random forest classifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import svm # for Support Vector Machine
from sklearn import metrics

pip install xgboost

from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
train_X = sc.fit_transform(train_X)
test_X = sc.fit_transform(test_X)

parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}

def models(train_X,train_y):
 #Logistic Regression    0
  log = LogisticRegression(random_state = 51, penalty = 'l2')
  log.fit(train_X,train_y)

  #Random Forest         1
  forest=RandomForestClassifier(n_estimators=2,criterion='entropy',random_state=42)
  forest.fit(train_X,train_y)


  # Decision tree        2
  tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=10, random_state=10)
  tree.fit(train_X,train_y)



  #Gradient Boosting     3
  gb_clf=GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42)
  gb_clf.fit(train_X,train_y)


  #Support Vector Machines  4
  svm =SVC()
  svm.fit(train_X,train_y)


  #k-Nearest Neighbors  5
  classifier = KNeighborsClassifier(algorithm="auto", leaf_size=30, metric="minkowski",metric_params=None, n_jobs=1, n_neighbors=5, p=2,weights="uniform")
  classifier.fit(train_X,train_y)


  #Adaboost Classifier   6
  clf = AdaBoostClassifier(n_estimators=80, random_state=40)
  clf.fit(train_X,train_y)


  #Gaussian            7
  gause_clf = GaussianNB()
  gause_clf.fit(train_X,train_y)

  #GridSearch CV       8
  cv=GridSearchCV(SVC(),parameters)
  cv.fit(train_X,train_y)


  #XGBclassifier      9
  xgb =XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20)
  xgb.fit(train_X,train_y)


  print('[0]Logistic Regression Training Accuracy:',log.score(train_X,train_y))
  print('[1]Random Forest Training Accuracy:',forest.score(train_X,train_y))
  print('[2]Decision tree Training Accuracy:',tree.score(train_X,train_y))
  print('[3]Gradient Boosting Training Accuracy:',gb_clf.score(train_X,train_y))
  print('[4]Support Vector Machines Training Accuracy:',svm.score(train_X,train_y))
  print('[5]k-Nearest Neighbors Training Accuracy:',classifier.score(train_X,train_y))
  print('[6]Adaboost Classifier Training Accuracy:',clf.score(train_X,train_y))
  print('[7]Gaussian Training Accuracy:',gause_clf.score(train_X,train_y))
  print('[8]GridSearch CV Training Accuracy:',cv.score(train_X,train_y))
  print('[9]XGBclassifier Training Accuracy:',xgb.score(train_X,train_y))

  return log,forest,tree,gb_clf,svm,classifier,clf,gause_clf,cv,xgb

model = models(train_X, train_y)

from sklearn.metrics import confusion_matrix,classification_report,log_loss,cohen_kappa_score
from sklearn import metrics
for i in range (len(model)):
  print('confusion matrix of model',i,'is:')
  cm=confusion_matrix(test_y,model[i].predict(test_X))
  TP=cm[0][0]
  TN=cm[1][1]
  FP=cm[0][1]
  FN=cm[1][0]
  print(cm)
  print()
  result1=classification_report(test_y,model[i].predict(test_X))
  print("Classification report:",)
  print(result1)
  print()
  var=((TP+TN)/(TP+TN+FP+FN))*100
  print('testing accuracy:',var)
  print('precision:',TP/(TP+FP))
  print('Specificity:',TN/(TN+FP))
  print('F1 score:',2*((TN/(TN+FP)) * (TP/(TP+FN)))/((TN/(TN+FP)) + (TP/(TP+FN))))
  print('Sensitivity/recall:',TP/(TP+FN))
  print('false positive rate:',FP/(FP+TN))
  print('False negative:',FN/(FN+TP))
  print('Negative Peridictive Value:',TN/(TN+FN))
  print('False Discovery rate:',FP/(TP+FP))
  print('Mean Absolute Eror:',metrics.mean_absolute_error(test_y,model[i].predict(test_X)))
  print('Mean Squared Error:',metrics.mean_squared_error(test_y,model[i].predict(test_X)))
  print('Root Mean Squared Error:',np.sqrt(metrics.mean_squared_error(test_y,model[i].predict(test_X))))
  print('log_loss:',metrics.log_loss(test_y,model[i].predict(test_X)))
  print('Ã‡ohen_Kappa_Scorer:',cohen_kappa_score(test_y,model[i].predict(test_X)))

  print()
  print()
  name=['LogisticRegression','RandomForestClassifier','DecisionTreeClassifier','GradientBoostingClassifier',
        'SVC','KNeighborsClassifier','AdaBoostClassifier','Gaussian','GridSearch CV','XGBClassifier']
  col_value=['blue','green','purple','blue','green','purple','green','blue','purple','blue','green','blue']
  model_accuracy=pd.Series(data=(var),index=[name[i]])
  fig=plt.figure(figsize=(5,5))
  width=0.75
  model_accuracy.sort_values().plot.bar(alpha=0.8,color=[col_value[i]])
  plt.xticks(rotation=0)
  plt.title('model Accuracy')
  plt.ylabel('Accuracy(%)')
  plt.show()
  print()
  print()

#set up plotting area
from sklearn.metrics import roc_curve,roc_auc_score
plt.figure(0).clf()

#fit logistic regression model and plot ROC curve
model = LogisticRegression(random_state = 51, penalty = 'l2')
model.fit(train_X, train_y)
y_pred = model.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Logistic, AUC="+str(auc))


#fit Gradient Boosting Classifier model and plot ROC curve
model = GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42)
model.fit(train_X, train_y)
y_pred = model.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Gradient Boosting Classifier, AUC="+str(auc))


#fit K-Neighbors Classifier model and plot ROC curve
model = KNeighborsClassifier(algorithm="auto", leaf_size=30, metric="minkowski",metric_params=None, n_jobs=1, n_neighbors=5, p=2,weights="uniform")
model.fit(train_X, train_y)
y_pred = model.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="K-Neighbors Classifier, AUC="+str(auc))


#fit SVC Classifier model and plot ROC curve
model = SVC(probability=True)
model.fit(train_X, train_y)
y_pred = model.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="SVC, AUC="+str(auc))


#fit Gaussian Classifier model and plot ROC curve
model = GaussianNB()
model.fit(train_X, train_y)
y_pred = model.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Gaussian Classifier, AUC="+str(auc))

#fit XGB Classifier model and plot ROC curve
model = XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20)
model.fit(train_X, train_y)
y_pred = model.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="XGBClassifier, AUC="+str(auc))

# Plot ROC curves
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")

#add legend
plt.legend()



#BAGGING

from sklearn.ensemble import BaggingClassifier
bg1=BaggingClassifier(LogisticRegression(random_state = 51, penalty = 'l2'),max_samples=0.5,
                     max_features=7,n_estimators=20)

bg1.fit(train_X, train_y)

bg1.score(test_X,test_y)

ypred1 = bg1.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred1, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import BaggingClassifier
bg2=BaggingClassifier(GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42),max_samples=0.5,
                     max_features=7,n_estimators=20)

bg2.fit(train_X, train_y)

bg2.score(test_X,test_y)

ypred2 = bg2.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred2, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import BaggingClassifier
bg3=BaggingClassifier(SVC(probability=True),max_samples=0.5,max_features=7,n_estimators=20)

bg3.fit(train_X, train_y)

bg3.score(test_X,test_y)

ypred3 = bg3.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred3, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import BaggingClassifier
bg4=BaggingClassifier(KNeighborsClassifier(algorithm="auto", leaf_size=30, metric="minkowski",metric_params=None, n_jobs=1, n_neighbors=5, p=2,weights="uniform"),max_samples=0.5,
                     max_features=7,n_estimators=20)

bg4.fit(train_X, train_y)

bg4.score(test_X,test_y)

ypred4 = bg4.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred4, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import BaggingClassifier
bg5=BaggingClassifier(GaussianNB(),max_samples=0.5, max_features=7,n_estimators=20)

bg5.fit(train_X, train_y)

bg5.score(test_X,test_y)

ypred5 = bg5.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred5, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import BaggingClassifier
bg6=BaggingClassifier(XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20),max_samples=0.5,
                     max_features=7,n_estimators=20)

bg6.fit(train_X, train_y)

bg6.score(test_X,test_y)

ypred6 = bg6.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred6, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

#set up plotting area
from sklearn.metrics import roc_curve,roc_auc_score
plt.figure(0).clf()

#fit GradientBoostingClassifier model and plot ROC curve
model1=BaggingClassifier(GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42),max_samples=0.5,
                     max_features=7,n_estimators=20)
model1.fit(train_X, train_y)
y_pred = model1.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc1 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Gradient Boosting, AUC-ROC="+str(auc1))


#fit Logistic Regression model and plot ROC curve
model2=BaggingClassifier(LogisticRegression(random_state = 51, penalty = 'l2'),max_samples=0.5,
                     max_features=7,n_estimators=20)
model2.fit(train_X, train_y)
y_pred = model2.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc2 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Random Forest, AUC-ROC="+str(auc2))


#fit SVC Classifier model and plot ROC curve
model3 = BaggingClassifier(SVC(probability=True),max_samples=0.5,max_features=7,n_estimators=20)
model3.fit(train_X, train_y)
y_pred = model3.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc3 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="SVC, AUC-ROC="+str(auc3))


#fit K-Neighbors Classifier model and plot ROC curve
model4 = BaggingClassifier(KNeighborsClassifier(algorithm="auto", leaf_size=30, metric="minkowski",metric_params=None, n_jobs=1, n_neighbors=5, p=2,weights="uniform"),max_samples=0.5,
                     max_features=7,n_estimators=20)
model4.fit(train_X, train_y)
y_pred = model4.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc4 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="K-Neighbors Classifier, AUC="+str(auc4))


#fit XGBClassifier model and plot ROC curve
model5 = BaggingClassifier(XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20),max_samples=0.5,
                     max_features=7,n_estimators=20)
model5.fit(train_X, train_y)
y_pred = model5.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc5 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="XGBClassifier, AUC="+str(auc5))



# Plot ROC curves
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")

#add legend
plt.legend()

#BOOSTING

from sklearn.ensemble import AdaBoostClassifier
bos1=AdaBoostClassifier(XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20),n_estimators=10)
bos1.fit(train_X, train_y)

bos1.score(test_X, test_y)

ypred1 = bos1.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred1, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import AdaBoostClassifier
bos2=AdaBoostClassifier(LogisticRegression(random_state = 51, penalty = 'l2'),n_estimators=10)
bos2.fit(train_X, train_y)

bos2.score(test_X, test_y)

ypred2 = bos2.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred2, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import AdaBoostClassifier
bos3=AdaBoostClassifier(GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42),n_estimators=10)
bos3.fit(train_X, train_y)

bos3.score(test_X, test_y)

ypred3 = bos3.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred3, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

from sklearn.ensemble import AdaBoostClassifier
bos4=AdaBoostClassifier(SVC(probability=True),n_estimators=10)
bos4.fit(train_X, train_y)

bos4.score(test_X, test_y)

ypred4 = bos4.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred4, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

#set up plotting area
from sklearn.metrics import roc_curve,roc_auc_score
plt.figure(0).clf()

#fit XGBClassifier model and plot ROC curve
model1=AdaBoostClassifier(XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20),n_estimators=10)
model1.fit(train_X, train_y)
y_pred = model1.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc1 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="XGBClassifier, AUC="+str(auc1))


#fit LogisticRegression model and plot ROC curve
model2=AdaBoostClassifier(LogisticRegression(random_state = 51, penalty = 'l2'),n_estimators=10)
model2.fit(train_X, train_y)
y_pred = model2.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc2 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Random Forest, AUC="+str(auc2))


#fit Gradient Boosting Classifier model and plot ROC curve
model3 = AdaBoostClassifier(GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42),n_estimators=10)
model3.fit(train_X, train_y)
y_pred = model3.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc3 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="GradientBoostingClassifier, AUC="+str(auc3))


#fit SVC Classifier model and plot ROC curve
model4 = AdaBoostClassifier(SVC(probability=True),n_estimators=10)
model4.fit(train_X, train_y)
y_pred = model4.predict_proba(test_X)[:, 1]
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc4 = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="SVC, AUC="+str(auc4))



# Plot ROC curves
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")

#add legend
plt.legend()



#STACKING

!pip install mlxtend
from sklearn.linear_model import LogisticRegression
from mlxtend.classifier import StackingClassifier

clf1=XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                     max_depth = 5, alpha = 10, n_estimators = 20)
clf2=LogisticRegression(random_state = 51, penalty = 'l2')
clf3=GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42)
clf4=KNeighborsClassifier(algorithm="auto", leaf_size=30, metric="minkowski",metric_params=None, n_jobs=1, n_neighbors=5, p=2,weights="uniform")
clf5=SVC(probability=True)
clf6=gause_clf = GaussianNB()
log=LogisticRegression(random_state=42 )
sclf=StackingClassifier(classifiers=[clf1,clf2,clf3,clf4,clf5,clf6],use_probas=True,meta_classifier=log)

sclf.fit(train_X, train_y)

sclf.score(test_X, test_y)

ypred = sclf.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

ypred = sclf.predict(test_X)
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Stacking AUC="+str(auc))

# Plot ROC curves
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.legend()







#VOTING

from sklearn.ensemble import VotingClassifier

# Commented out IPython magic to ensure Python compatibility.
# %%time
# L= LogisticRegression(random_state = 51, penalty = 'l2')
# S= RandomForestClassifier(n_estimators=2,criterion='entropy',random_state=42)
# G= GradientBoostingClassifier ( n_estimators=30,max_features=1,random_state=42)
# #K= GaussianNB()
# #M=GridSearchCV(SVC(probability=True),parameters)
# #D=DecisionTreeClassifier(criterion = 'entropy', max_depth=10, random_state=10)
# evc = VotingClassifier(estimators=[('M',M),('L',L),('S',S),('G',G),('K',K)],voting='soft' )
# evc.fit(train_X,train_y)
# evc.score(test_X,test_y)

ypred9 = evc.predict(test_X)
pr, rc, fs, sup = metrics.precision_recall_fscore_support(test_y, ypred9, average='macro')
print("precision :", pr)
print("Recall :", rc)
print("F1 Score :", fs)

ypred = evc.predict(test_X)
fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)
auc = round(metrics.roc_auc_score(test_y, y_pred), 4)
plt.plot(fpr,tpr,label="Voting AUC-ROC="+str(auc))

# Plot ROC curves
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.legend()

plt.figure(figsize=(15,15))
matrix = np.triu(df.corr())
sns.heatmap(df.corr(), annot=True, mask=matrix)

